{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDVKLojIZbzN"
   },
   "source": [
    "# Data Analisis Assignment - Group 1\n",
    "## Introduction\n",
    "The goal of this project is to analyze hourly electricity generation in Spain, broken down by autonomous community and generation technology. We aim to extract and explore key insights from the data, identify regional and technological trends, and optionally examine correlations between different data sources.\n",
    "## Task 1: Data Extraction and Saving\n",
    "The data extraction process is carried out through the Red ElÃ©ctrica de EspaÃ±a (REE) API. An interactive user interface allows users to input the desired autonomous community and time period. Based on these inputs, the program retrieves the corresponding hourly electricity generation data and exports it to an Excel file named in the format: \"Generation_[AutonomousCommunity][StartDate][EndDate]\".\n",
    "\n",
    "__Inputs:__\n",
    "- Region Code\n",
    "- Start Date\n",
    "- End Date\n",
    "\n",
    "__Output:__\n",
    "- Excel file with columns: datetime, value by technology, percentage value by technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGgwIPnqZbzQ",
    "outputId": "998b8525-1228-447f-bbde-1b20e6adb082"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Geo_id per region according to the REE API:\n",
    "# https://www.ree.es/es/datos/apidatos\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Dictionary REGIONS  â†’  readable key  â†’  API id\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "REGIONES = {\n",
    "    \"AndalucÃ­a\": 4,\n",
    "    \"AragÃ³n\": 5,\n",
    "    \"Cantabria\": 6,\n",
    "    \"Asturias\": 11,\n",
    "    \"Castilla y LeÃ³n\": 8,\n",
    "    \"Castilla-La Mancha\": 7,\n",
    "    \"CataluÃ±a\": 9,\n",
    "    \"Comunidad Valenciana\": 15,\n",
    "    \"Extremadura\": 16,\n",
    "    \"Galicia\": 17,\n",
    "    \"Madrid\": 8752,\n",
    "    \"Murcia\": 21,\n",
    "    \"Navarra\": 14,\n",
    "    \"PaÃ­s Vasco\": 10,\n",
    "    \"La Rioja\": 20,\n",
    "    \"Islas Baleares\": 8743,\n",
    "    \"Islas Canarias\": 8742,\n",
    "    \"Ceuta\": 8744,\n",
    "    \"Melilla\": 8745,\n",
    "    \"PenÃ­nsula\": 8741,\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Interactive selection (region + dates)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
    "print(\"â•‘   Available Regions (geo_limit=ccaa)     â•‘\")\n",
    "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "for n, reg in enumerate(REGIONES, 1):\n",
    "    print(f\"{n:>2}. {reg}\")\n",
    "\n",
    "# --- Select region ---\n",
    "while True:\n",
    "    try:\n",
    "        idx = int(input(\"\\nNumber of desired region: \"))\n",
    "        region_name = list(REGIONES)[idx - 1]\n",
    "        geo_id = REGIONES[region_name]\n",
    "        break\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"â›” Invalid choice, try againâ€¦\")\n",
    "\n",
    "# --- Date input ---\n",
    "def ask_date(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            txt = input(prompt)\n",
    "            return dt.strptime(txt.strip(), \"%Y-%m-%d %H:%M\")\n",
    "        except ValueError:\n",
    "            print(\"â›” Invalid format. Example: 2019-01-01 00:00\")\n",
    "\n",
    "start = ask_date(\"\\nStart date (YYYY-MM-DD HH:MM): \")\n",
    "end   = ask_date(\"End date   (YYYY-MM-DD HH:MM): \")\n",
    "if end <= start:\n",
    "    raise ValueError(\"End date must be after the start date.\")\n",
    "\n",
    "print(f\"\\nâ–¶ Region: {region_name}  (geo_id = {geo_id})\")\n",
    "print(f\"â–¶ Period: {start}  â†’  {end}\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. API call function (daily granularity)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_gen(geo_id, start_date, end_date):\n",
    "    url = \"https://apidatos.ree.es/es/datos/generacion/estructura-generacion\"\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"time_trunc\": \"day\",\n",
    "        \"geo_limit\":  \"ccaa\",\n",
    "        \"geo_id\": geo_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"â›” Error {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame()  # <- Return empty DataFrame on failure\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract generation data\n",
    "    rows = []\n",
    "    for technology in data[\"included\"]:\n",
    "        name = technology[\"attributes\"][\"title\"]\n",
    "        for v in technology[\"attributes\"][\"values\"]:\n",
    "            rows.append({\n",
    "                \"datetime\": v[\"datetime\"],\n",
    "                \"value\": v[\"value\"],\n",
    "                \"percentage\": v[\"percentage\"],\n",
    "                \"technology\": name\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Call API\n",
    "df = get_gen(geo_id, start, end)\n",
    "\n",
    "\n",
    "if df.empty:\n",
    "    print(\"â— No data found. Please verify your input.\")\n",
    "else:\n",
    "    print(df.head())\n",
    "    # Format dates to string\n",
    "    start_str = start.strftime(\"%Y%m%d\")\n",
    "    end_str   = end.strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Export to Excel\n",
    "    archivo_excel = f\"generacion_{region_name.replace(' ', '_').lower()}_{start_str}_{end_str}.xlsx\"\n",
    "    df.to_excel(archivo_excel, index=False)\n",
    "    print(f\"âœ… Data saved to: {archivo_excel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zinSbb3VZbzV"
   },
   "source": [
    "## Task 2: Data Preprocessing and Cleaning\n",
    "\n",
    "__Inputs:__\n",
    "- dataframe \"df\" with columns: datetime, value, percentage, technology\n",
    "\n",
    "__Output:__\n",
    "- dataframe 'daily_pivot': Containing the daily production values and percentages of each techonlogy\n",
    "- dataframe 'monthly_pivot': Containing the monthly production values and percentages of each techonlogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VxA2A_KWZbzV",
    "outputId": "eb536a0a-f4ec-495b-fbe3-80bd73239da4"
   },
   "outputs": [],
   "source": [
    "# Display the top 5 rows of the Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABvAhK-_ZbzV",
    "outputId": "33004cc2-da3f-44b9-d8f8-cf4cdc78e4ed"
   },
   "outputs": [],
   "source": [
    "# Display information about the data including the index dtype and columns, non-null values and memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "D16SrYRMZbzW",
    "outputId": "464f3878-cd53-41d2-e3cb-f1cf3e83ac66"
   },
   "outputs": [],
   "source": [
    "# Display descriptive statistics include those that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV9RIx5IZbzW",
    "outputId": "f5cc4460-0ae7-43f8-fb7d-1949d99a8979"
   },
   "outputs": [],
   "source": [
    "# Check data for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Filter columns with missing values\n",
    "missing_cols = missing_values[missing_values > 0]\n",
    "\n",
    "# Print results\n",
    "if missing_cols.empty:\n",
    "    print(\"No null values found.\")\n",
    "else:\n",
    "    print(\"Missing values found in the following columns:\")\n",
    "    print(missing_cols)\n",
    "    print(\"\\nPossible treatments:\")\n",
    "    print(\"- Drop rows with missing values: df.dropna(inplace=True)\")\n",
    "    print(\"- Fill missing values (example: fill with mean): df.fillna(df.mean(), inplace=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnK7Z0qjgyG5"
   },
   "outputs": [],
   "source": [
    "# Convert datetime column\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxmk6GOWmnv1"
   },
   "outputs": [],
   "source": [
    "# Sort by datetime just in case\n",
    "df = df.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F34MlWMm8i_"
   },
   "source": [
    "### Dataframe restructure:\n",
    "The dataframe 'df' now is structured like in the columns:\n",
    "- datetime\n",
    "- value\n",
    "- percentage\n",
    "- technology\n",
    "\n",
    "Note that all the first dates of a month contain two values: one for the actual value and percentage of the technology of that date and one for the cummulated value and percentage of the month.\n",
    "\n",
    "To fix this the dataframe is restructured into two resulting ones. One with the monthly statistics and one with the daily statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "6pNzp_j_hS7U",
    "outputId": "d6c40dfc-67c2-4b60-9ba7-b1e7977d3844"
   },
   "outputs": [],
   "source": [
    "# Restructure to get the dataframe for the daily data.\n",
    "# Output structure: datetime\tvalue_[technology]\tpercentage_[technology]\n",
    "\n",
    "# Drop the cumulative rows â€” keep only the first daily entry\n",
    "daily_df = df.copy()\n",
    "daily_df['day'] = daily_df['datetime'].dt.date\n",
    "\n",
    "# For each day and technology, keep only the minimum value (assuming the cumulative has higher value)\n",
    "daily_df = daily_df.sort_values(['datetime', 'technology', 'value']).drop_duplicates(['day', 'technology'], keep='first')\n",
    "\n",
    "# Pivot to wide format\n",
    "daily_pivot = daily_df.pivot(index='datetime', columns='technology', values=['value', 'percentage'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "daily_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in daily_pivot.columns]\n",
    "daily_pivot = daily_pivot.reset_index()\n",
    "\n",
    "# Check for the results\n",
    "daily_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "Z1fHqEffokeG",
    "outputId": "db4c840a-a0c0-444f-c6b1-e8381b741af4"
   },
   "outputs": [],
   "source": [
    "# Restructure to get the dataframe for the monthly data.\n",
    "# Output structure: datetime\tvalue_[technology]\tpercentage_[technology]\n",
    "\n",
    "# Get cumulative values: assume they are the maximum for each technology on the first day of the month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['month'] = df['datetime'].dt.to_period('M')\n",
    "\n",
    "# Filter to first day of month\n",
    "monthly_df = df[df['day'] == 1]\n",
    "\n",
    "# For each month and technology, keep the **max** value (cumulative)\n",
    "monthly_cum = monthly_df.sort_values(['value'], ascending=False).drop_duplicates(['month', 'technology'], keep='first')\n",
    "\n",
    "# Pivot to wide format\n",
    "monthly_pivot = monthly_cum.pivot(index='month', columns='technology', values=['value', 'percentage'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "monthly_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in monthly_pivot.columns]\n",
    "monthly_pivot = monthly_pivot.reset_index()\n",
    "\n",
    "# Check for the results\n",
    "monthly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6hZRI23QZbzW",
    "outputId": "fe0ac55e-d34a-497a-abf9-93e0bb5b4c39"
   },
   "outputs": [],
   "source": [
    "# Check daily data for outliers values\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume daily_pivot is already prepared as described earlier\n",
    "# Exclude 'datetime' column\n",
    "data = daily_pivot.select_dtypes(include=[np.number])\n",
    "\n",
    "# -------------------------\n",
    "# 1. Z-score Method\n",
    "# -------------------------\n",
    "z_scores = np.abs(stats.zscore(data, nan_policy='omit'))\n",
    "z_outliers = (z_scores > 3)\n",
    "\n",
    "z_outlier_cols = data.columns[(z_outliers.sum(axis=0) > 0)].tolist()\n",
    "\n",
    "# -------------------------\n",
    "# 2. IQR Method\n",
    "# -------------------------\n",
    "iqr_outlier_cols = []\n",
    "for col in data.columns:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    outliers = data[(data[col] < lower) | (data[col] > upper)]\n",
    "    if not outliers.empty:\n",
    "        iqr_outlier_cols.append(col)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Boxplot Visualization\n",
    "# -------------------------\n",
    "for col in data.columns:\n",
    "    plt.figure()\n",
    "    plt.boxplot(data[col].dropna())\n",
    "    plt.title(f'Boxplot for {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 4. Summary Output\n",
    "# -------------------------\n",
    "if not z_outlier_cols and not iqr_outlier_cols:\n",
    "    print(\"âœ… No outliers found using Z-score or IQR methods.\")\n",
    "else:\n",
    "    all_outlier_cols = sorted(set(z_outlier_cols + iqr_outlier_cols))\n",
    "    print(\"âš ï¸ Outliers detected in the following columns:\")\n",
    "    for col in all_outlier_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Optional treatment (e.g., replacing with NaN or clipping)\n",
    "    # Example: Replace extreme Z-score outliers with NaN\n",
    "    for col in all_outlier_cols:\n",
    "        daily_pivot.loc[z_outliers[:, data.columns.get_loc(col)], col] = np.nan\n",
    "\n",
    "    print(\"\\nðŸ“Œ Treatment applied: Replaced Z-score outliers (>3Ïƒ) with NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fAupAiV4qT8h",
    "outputId": "f2e1ae6c-5bb2-432c-aa23-ce8e15a72545"
   },
   "outputs": [],
   "source": [
    "# Check for outliers in monthly data\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume monthly_pivot is already prepared\n",
    "# Remove 'month' column for numeric analysis\n",
    "data = monthly_pivot.select_dtypes(include=[np.number])\n",
    "\n",
    "# -------------------------\n",
    "# 1. Z-score Method\n",
    "# -------------------------\n",
    "z_scores = np.abs(stats.zscore(data, nan_policy='omit'))\n",
    "z_outliers = (z_scores > 3)\n",
    "\n",
    "z_outlier_cols = data.columns[(z_outliers.sum(axis=0) > 0)].tolist()\n",
    "\n",
    "# -------------------------\n",
    "# 2. IQR Method\n",
    "# -------------------------\n",
    "iqr_outlier_cols = []\n",
    "for col in data.columns:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    outliers = data[(data[col] < lower) | (data[col] > upper)]\n",
    "    if not outliers.empty:\n",
    "        iqr_outlier_cols.append(col)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Boxplot Visualization\n",
    "# -------------------------\n",
    "for col in data.columns:\n",
    "    plt.figure()\n",
    "    plt.boxplot(data[col].dropna())\n",
    "    plt.title(f'Boxplot for {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 4. Summary Output\n",
    "# -------------------------\n",
    "if not z_outlier_cols and not iqr_outlier_cols:\n",
    "    print(\"âœ… No outliers found in monthly data using Z-score or IQR methods.\")\n",
    "else:\n",
    "    all_outlier_cols = sorted(set(z_outlier_cols + iqr_outlier_cols))\n",
    "    print(\"âš ï¸ Outliers detected in the following columns of monthly data:\")\n",
    "    for col in all_outlier_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Optional treatment: Replace Z-score outliers with NaN\n",
    "    for col in all_outlier_cols:\n",
    "        monthly_pivot.loc[z_outliers[:, data.columns.get_loc(col)], col] = np.nan\n",
    "\n",
    "    print(\"\\nðŸ“Œ Treatment applied: Z-score outliers (>3Ïƒ) replaced with NaN in monthly data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ggLShmJZbzW",
    "outputId": "e43ec572-10bf-4c32-828a-07f9d9a06121"
   },
   "outputs": [],
   "source": [
    "# Check data for duplicate values in daily_pivot\n",
    "duplicates = daily_pivot.duplicated()\n",
    "\n",
    "if not duplicates.any():\n",
    "    print(\"âœ… No duplicates found in daily data.\")\n",
    "else:\n",
    "    num_duplicates = duplicates.sum()\n",
    "    print(f\"âš ï¸ {num_duplicates} duplicate rows found in daily data.\")\n",
    "    daily_pivot = daily_pivot.drop_duplicates()\n",
    "    print(\"ðŸ§¹ Treatment applied: Duplicate rows were removed from daily data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YotKfy7grFr5",
    "outputId": "61eb7802-6fc3-49b7-d33e-1e58a24ac0fe"
   },
   "outputs": [],
   "source": [
    "# Check data for duplicate values in monthly_pivot\n",
    "duplicates = monthly_pivot.duplicated()\n",
    "\n",
    "if not duplicates.any():\n",
    "    print(\"âœ… No duplicates found in monthly data.\")\n",
    "else:\n",
    "    num_duplicates = duplicates.sum()\n",
    "    print(f\"âš ï¸ {num_duplicates} duplicate rows found in monthly data.\")\n",
    "    monthly_pivot = monthly_pivot.drop_duplicates()\n",
    "    print(\"ðŸ§¹ Treatment applied: Duplicate rows were removed from monthly data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "399bjEqFr2eE",
    "outputId": "1c01f4fa-0009-4d31-aa5d-1c787d9f6b43"
   },
   "outputs": [],
   "source": [
    "# Check for NaN/null values in daily_pivot\n",
    "null_counts = daily_pivot.isnull().sum()\n",
    "total_null_rows = daily_pivot.isnull().any(axis=1).sum()\n",
    "\n",
    "if total_null_rows == 0:\n",
    "    print(\"âœ… No NaN/null values found in daily data.\")\n",
    "else:\n",
    "    print(\"âš ï¸ NaN/null values found in the following columns of daily data:\")\n",
    "    print(null_counts[null_counts > 0])\n",
    "    print(f\"ðŸ§¹ Total rows with NaNs to be removed: {total_null_rows}\")\n",
    "\n",
    "    # Drop rows with any NaNs\n",
    "    daily_pivot = daily_pivot.dropna()\n",
    "    print(\"ðŸ“Œ Treatment applied: Rows with NaN values were dropped from daily data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uzhTf2Zsr9w",
    "outputId": "bfc780f4-6479-45b6-caa2-fc7e937709d2"
   },
   "outputs": [],
   "source": [
    "# Check for NaN/null values in monthly_pivot\n",
    "null_counts = monthly_pivot.isnull().sum()\n",
    "total_null_rows = monthly_pivot.isnull().any(axis=1).sum()\n",
    "\n",
    "if total_null_rows == 0:\n",
    "    print(\"âœ… No NaN/null values found in monthly data.\")\n",
    "else:\n",
    "    print(\"âš ï¸ NaN/null values found in the following columns of monthly data:\")\n",
    "    print(null_counts[null_counts > 0])\n",
    "    print(f\"ðŸ§¹ Total rows with NaNs to be removed: {total_null_rows}\")\n",
    "\n",
    "    # Drop rows with any NaNs\n",
    "    monthly_pivot = monthly_pivot.dropna()\n",
    "    print(\"ðŸ“Œ Treatment applied: Rows with NaN values were dropped from monthly data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_Klxkaqw1Ia",
    "outputId": "b9b31783-3117-4da8-f8de-f9075cddb24b"
   },
   "outputs": [],
   "source": [
    "# Information about daily_pivot\n",
    "daily_pivot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Xhg7IgSOxRyy",
    "outputId": "8f6bad2a-960c-4d69-f5b2-a38faf5b11df"
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics about daily_pivot\n",
    "daily_pivot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgnF3VAcxJpK",
    "outputId": "64135bc6-875f-4b4c-dc46-ccde8db1ba4a"
   },
   "outputs": [],
   "source": [
    "# Information about monthly_pivot\n",
    "monthly_pivot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "c3c7mTDAxly2",
    "outputId": "0df0799c-4bb1-43ab-b771-252e5df46b35"
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics about monthly_pivot\n",
    "monthly_pivot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04D3bvbRZbzS"
   },
   "source": [
    "## Task 3: Data Visualization and Insights Extraction\n",
    "\n",
    "This code transforms raw time-series (hourly or daily) data into insightful visualizations by aggregating daily generation values by different time periods (day or week) and presenting them by technology type.\n",
    "\n",
    "__Input:__\n",
    "Dataframe 'df' with columns:\n",
    "- datetime\n",
    "- value\n",
    "- percentage\n",
    "- technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "Tpna340uZbzT",
    "outputId": "f11767ba-375a-4cd5-9657-bb63fdf54ae2"
   },
   "outputs": [],
   "source": [
    "# Daily Energy Generation Bar Graph by Technology\n",
    "# Exclusive of last date in range\n",
    "# This sums hourly values for each day, in case hourly data becomes available in this widget in the future\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "\n",
    "# Remove all rows corresponding to the last date in the dataset (the values are abnormally low)\n",
    "df_truncated = df[df[\"date\"] != df[\"date\"].max()]\n",
    "\n",
    "# Remove monthly sum values, which are the larger of two values for each tech on the 1st of the month\n",
    "# Sort so that the larger values come last, and keep only the first\n",
    "df_truncated = df_truncated.sort_values([\"technology\", \"date\", \"value\"], ascending=[True, True, True])\n",
    "df_clean = df_truncated.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "pivot_df = df_clean.pivot_table(\n",
    "    index=\"date\",\n",
    "    columns=\"technology\",\n",
    "    values=\"value\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    "    )\n",
    "\n",
    "pivot_df_indiv = pivot_df.drop(columns=\"GeneraciÃ³n total\", errors=\"ignore\")\n",
    "\n",
    "pivot_df_indiv.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    title=f\"Daily generation by technology in Spain\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Generation (MWh)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Technology\", loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "UmTLSE9dZbzT",
    "outputId": "25e03969-1f8c-4be7-bbde-0bd8890a1ef3"
   },
   "outputs": [],
   "source": [
    "# Daily Energy Generation Percentage Bar Graph by Technology\n",
    "# Exclusive of last date in range\n",
    "# This sums hourly percentages for each day, in case hourly data becomes available in this widget in the future\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "\n",
    "# Remove all rows corresponding to the last date in the dataset (the values are abnormally low)\n",
    "df_truncated = df[df[\"date\"] != df[\"date\"].max()]\n",
    "\n",
    "# Remove monthly sum percentages, which are the smaller of two values for each tech on the 1st of the month\n",
    "# Sort so that the smaller percentages come last, and keep only the first\n",
    "df_truncated = df_truncated.sort_values([\"technology\", \"date\", \"percentage\"], ascending=[True, True, False])\n",
    "df_clean = df_truncated.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "pivot_df = df_clean.pivot_table(\n",
    "    index=\"date\",\n",
    "    columns=\"technology\",\n",
    "    values=\"percentage\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    "    )\n",
    "\n",
    "pivot_df_indiv = pivot_df.drop(columns=\"GeneraciÃ³n total\", errors=\"ignore\")\n",
    "\n",
    "pivot_df_indiv.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    title=f\"Daily generation percentage by technology in Spain\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Generation (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Technology\", loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "TztxXdpZZbzU",
    "outputId": "b4e26b8b-6912-41eb-c8ca-672e1d1deb2c"
   },
   "outputs": [],
   "source": [
    "# Weekly Energy Generation Share Bar Graph by Technology\n",
    "# exclusive of last date in range\n",
    "# This aggregates percentage values for complete weeks only (starting on Mondays)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "\n",
    "# Remove all rows corresponding to the last date in the dataset (the values are abnormally low)\n",
    "df_truncated = df[df[\"date\"] != df[\"date\"].max()]\n",
    "\n",
    "# Remove monthly sum values, which are the larger of two values for each tech on the 1st of the month\n",
    "# Sort so that the larger values come last, and keep only the first\n",
    "df_truncated = df_truncated.sort_values([\"technology\", \"date\", \"value\"], ascending=[True, True, True])\n",
    "df_clean = df_truncated.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "# Add weekly period starting on Monday\n",
    "df_clean[\"week\"] = pd.to_datetime(df_clean[\"date\"]).dt.to_period(\"W-MON\")\n",
    "\n",
    "# Count number of days per week\n",
    "week_counts = df_clean.groupby(\"week\")[\"date\"].nunique()\n",
    "full_weeks = week_counts[week_counts == 7].index\n",
    "\n",
    "# Keep only data from full weeks\n",
    "df_clean = df_clean[df_clean[\"week\"].isin(full_weeks)]\n",
    "\n",
    "# Pivot the cleaned dataframe\n",
    "pivot_df = df_clean.pivot_table(\n",
    "    index=\"week\",\n",
    "    columns=\"technology\",\n",
    "    values=\"value\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "pivot_df_indiv = pivot_df.drop(columns=\"GeneraciÃ³n total\", errors=\"ignore\")\n",
    "\n",
    "pivot_df_indiv.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    title=f\"Weekly generation by technology in Spain\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Generation (MWh)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Technology\", loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "dehwt8quZbzU",
    "outputId": "48f45a0d-8492-49f2-f362-ef9c65323d73"
   },
   "outputs": [],
   "source": [
    "# Weekly Energy Generation Share Bar Graph by Technology (Percentage)\n",
    "# exclusive of last date in range\n",
    "# This aggregates percentage values for complete weeks only (starting on Mondays)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "\n",
    "# Remove all rows corresponding to the last date in the dataset (the values are abnormally low)\n",
    "df_truncated = df[df[\"date\"] != df[\"date\"].max()]\n",
    "\n",
    "# Remove monthly sum percentages, which are the smaller of two values for each tech on the 1st of the month\n",
    "# Sort so that the smaller percentages come last, and keep only the first\n",
    "df_truncated = df_truncated.sort_values([\"technology\", \"date\", \"percentage\"], ascending=[True, True, False])\n",
    "df_clean = df_truncated.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "# Add weekly period starting on Monday\n",
    "df_clean[\"week\"] = pd.to_datetime(df_clean[\"date\"]).dt.to_period(\"W-MON\")\n",
    "\n",
    "# Count number of days per week\n",
    "week_counts = df_clean.groupby(\"week\")[\"date\"].nunique()\n",
    "full_weeks = week_counts[week_counts == 7].index\n",
    "\n",
    "# Keep only data from full weeks\n",
    "df_clean = df_clean[df_clean[\"week\"].isin(full_weeks)]\n",
    "\n",
    "# Pivot the cleaned dataframe\n",
    "pivot_df = df_clean.pivot_table(\n",
    "    index=\"week\",\n",
    "    columns=\"technology\",\n",
    "    values=\"percentage\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "pivot_df_indiv = pivot_df.drop(columns=\"GeneraciÃ³n total\", errors=\"ignore\")\n",
    "\n",
    "pivot_df_indiv.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    title=f\"Weekly generation share by technology in Spain (%)\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Share of Generation (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Technology\", loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "id": "JBpxQj7EZbzU",
    "outputId": "bb6738bb-2631-466c-efc2-3dbf0aea5839"
   },
   "outputs": [],
   "source": [
    "# Daily Energy Generation Line Charts by Technology\n",
    "# This script lets the user select a technology from the dataset and shows two line charts:\n",
    "# one for daily total production (in MWh) and one for average daily percentage.\n",
    "# It groups and sums values by day to visualize trends over time.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "\n",
    "# Get unique technologies and create the dynamic menu\n",
    "tech_list = sorted(df['technology'].unique())\n",
    "\n",
    "df_trunc = df[df[\"date\"] != df[\"date\"].max()]\n",
    "\n",
    "df_trunc_val = df_trunc.sort_values([\"technology\", \"date\", \"value\"], ascending=[True, True, True])\n",
    "df_trunc_val = df_trunc_val.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "df_trunc_perc = df_trunc.sort_values([\"technology\", \"date\", \"percentage\"], ascending=[True, True, False])\n",
    "df_trunc_perc = df_trunc_perc.drop_duplicates(subset=[\"date\", \"technology\"], keep=\"first\")\n",
    "\n",
    "# Menu and input loop\n",
    "selected_tech = None\n",
    "while selected_tech is None:\n",
    "    print(\"\\nSelect a technology to generate the chart:\\n\")\n",
    "    for idx, tech in enumerate(tech_list, start=1):\n",
    "        print(f\"{idx}. {tech}\")\n",
    "\n",
    "    user_input = input(\"\\nEnter the number of the selected technology: \")\n",
    "    try:\n",
    "        choice = int(user_input)\n",
    "        if 1 <= choice <= len(tech_list):\n",
    "            selected_tech = tech_list[choice - 1]\n",
    "        else:\n",
    "            print(\"Number out of range. Please try again.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "print(f\"\\nYou selected: {selected_tech}\")\n",
    "\n",
    "df_val_filtered = df_trunc_val[df_trunc_val['technology'] == selected_tech]\n",
    "df_perc_filtered = df_trunc_perc[df_trunc_perc['technology'] == selected_tech]\n",
    "\n",
    "grouped_val = df_val_filtered.groupby('date')['value'].sum().reset_index()\n",
    "grouped_perc = df_perc_filtered.groupby('date')['percentage'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(grouped_val['date'], grouped_val['value'], marker='o')\n",
    "plt.title(f'Daily Production - {selected_tech}')\n",
    "plt.ylabel('Production (MWh)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(grouped_perc['date'], grouped_perc['percentage'], marker='o', color='orange')\n",
    "plt.title(f'Daily Share of Total Production - {selected_tech}')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGtQ00kkZbzW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 4: Comparison of the results of the different sources\n",
    "\n",
    "__Inputs:__\n",
    "- Data of Red ElÃ©ctrica de EspaÃ±a (REE) API\n",
    "- Wind data from maritime observations in NOOA corresponding to the Spanish coasts (Group 4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
